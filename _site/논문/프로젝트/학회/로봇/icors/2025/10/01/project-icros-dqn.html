<!DOCTYPE html>
<html lang="kr">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie-edge">

<!-- Google Fonts: Noto Sans KR (본문/제목) & Source Code Pro (코드) -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&family=Source+Code+Pro&display=swap" rel="stylesheet">

<link rel="stylesheet" href="/assets/css/style.css">
<title>Deformable Object Manipulation Policy Learning by DQN</title>
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Deformable Object Manipulation Policy Learning by DQN | 혁준의 블로그</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Deformable Object Manipulation Policy Learning by DQN" />
<meta name="author" content="Hyeokjun Kwon" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="본 포스트에서는 2024년 3월 ~ 12월, 교내 교수학습센터의 지원을 받아 1저자로서 주도했던 ‘의류 정리 로봇’ 연구에 대해 기록하고자 합니다. 이 연구는 딥러닝 비전 기술과 강화학습을 결합하여 로봇이 스스로 의류(수건)를 접는 방법을 학습하는 가능성을 탐구했으며, 그 성과를 제어로봇시스템학회(ICROS) 2025에 발표하게 되었습니다." />
<meta property="og:description" content="본 포스트에서는 2024년 3월 ~ 12월, 교내 교수학습센터의 지원을 받아 1저자로서 주도했던 ‘의류 정리 로봇’ 연구에 대해 기록하고자 합니다. 이 연구는 딥러닝 비전 기술과 강화학습을 결합하여 로봇이 스스로 의류(수건)를 접는 방법을 학습하는 가능성을 탐구했으며, 그 성과를 제어로봇시스템학회(ICROS) 2025에 발표하게 되었습니다." />
<link rel="canonical" href="http://localhost:4000/%EB%85%BC%EB%AC%B8/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%ED%95%99%ED%9A%8C/%EB%A1%9C%EB%B4%87/icors/2025/10/01/project-icros-dqn.html" />
<meta property="og:url" content="http://localhost:4000/%EB%85%BC%EB%AC%B8/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%ED%95%99%ED%9A%8C/%EB%A1%9C%EB%B4%87/icors/2025/10/01/project-icros-dqn.html" />
<meta property="og:site_name" content="혁준의 블로그" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-01T11:03:33+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Deformable Object Manipulation Policy Learning by DQN" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Hyeokjun Kwon"},"dateModified":"2025-10-01T11:03:33+09:00","datePublished":"2025-10-01T11:03:33+09:00","description":"본 포스트에서는 2024년 3월 ~ 12월, 교내 교수학습센터의 지원을 받아 1저자로서 주도했던 ‘의류 정리 로봇’ 연구에 대해 기록하고자 합니다. 이 연구는 딥러닝 비전 기술과 강화학습을 결합하여 로봇이 스스로 의류(수건)를 접는 방법을 학습하는 가능성을 탐구했으며, 그 성과를 제어로봇시스템학회(ICROS) 2025에 발표하게 되었습니다.","headline":"Deformable Object Manipulation Policy Learning by DQN","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/%EB%85%BC%EB%AC%B8/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%ED%95%99%ED%9A%8C/%EB%A1%9C%EB%B4%87/icors/2025/10/01/project-icros-dqn.html"},"url":"http://localhost:4000/%EB%85%BC%EB%AC%B8/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%ED%95%99%ED%9A%8C/%EB%A1%9C%EB%B4%87/icors/2025/10/01/project-icros-dqn.html"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>
</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/portfolio.png" alt="Hyeokjun Kwon" />
        
      </a>
      <h2 id="title">
        <a href="/">Hyeokjun Kwon</a>
      </h2>
      </div><p class="tagline">Developer & Creator</p></div>
      
      <ul class="social about-footer condensed"><a href="https://github.com/lemonzamong" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/hyeokjun-kwon-6022912b1" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://instagram.com/jjjun_04" target="_blank">
          <li>
            <i class="icon-instagram"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/%EB%85%BC%EB%AC%B8/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%ED%95%99%ED%9A%8C/%EB%A1%9C%EB%B4%87/icors/2025/10/01/project-icros-dqn.html">
    <h2 class="post-title">Deformable Object Manipulation Policy Learning by DQN</h2>
  </a>
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Oct 1, 2025</div><ul class="post-categories"><li>논문</li><li>프로젝트</li><li>학회</li><li>로봇</li><li>ICORS</li></ul></div>
  <div class="post">
    <p>본 포스트에서는 2024년 3월 ~ 12월, 교내 교수학습센터의 지원을 받아 1저자로서 주도했던 ‘의류 정리 로봇’ 연구에 대해 기록하고자 합니다. 이 연구는 딥러닝 비전 기술과 강화학습을 결합하여 로봇이 스스로 의류(수건)를 접는 방법을 학습하는 가능성을 탐구했으며, 그 성과를 <strong>제어로봇시스템학회(ICROS) 2025에 발표</strong>하게 되었습니다.</p>

<h2 id="서론-introduction">서론 (Introduction)</h2>

<h3 id="필요성-및-목적">필요성 및 목적</h3>
<p>고령화 사회가 심화되면서 빨래 개기와 같은 일상적인 가사 노동은 노인이나 신체적 제약이 있는 이들에게 큰 부담이 됩니다. 본 연구는 이러한 문제를 해결하기 위해, 로봇이 스스로 의류를 인식하고 효율적으로 접는 작업을 자동화하는 ‘가정용 보조 로봇’ 기술의 기반을 마련하는 것을 목표로 합니다. 복잡한 의류 대신, 비정형 객체 조작의 핵심 원리를 탐구하기 위해 ‘수건’을 연구 대상으로 선정했습니다.</p>

<h3 id="연구의-핵심-과제">연구의 핵심 과제</h3>
<ol>
  <li><strong>인식 (Perception):</strong> 로봇이 어떻게 다양한 환경 속에서 수건을 정확히 보고 인식할 수 있을까?</li>
  <li><strong>조작 (Manipulation):</strong> 로봇이 어떤 순서로 행동해야 가장 효율적으로 수건을 접을 수 있는지, 그 ‘정책(Policy)’을 어떻게 학습할 수 있을까?</li>
</ol>

<h3 id="핵심-아이디어">핵심 아이디어</h3>
<p>저희는 이 두 가지 과제를 해결하기 위해 시스템을 두 개의 핵심 모듈로 나누어 접근했습니다.</p>
<ul>
  <li><strong>비전 모듈:</strong> CNN 기반의 딥러닝 모델을 사용하여 웹캠 영상만으로 실시간으로 수건을 강건하게 탐지합니다.</li>
  <li><strong>제어 모듈:</strong> 강화학습(DQN)을 이용해 로봇이 수많은 시행착오를 통해 최적의 접기 동작 순서를 스스로 학습하도록 합니다.</li>
</ul>

<h2 id="1-실시간-수건-인식을-위한-비전-모듈">1. 실시간 수건 인식을 위한 비전 모듈</h2>

<p>[그림 1: 웹캠을 통한 실시간 수건 인식]
<img src="/assets/img/project-icros-dqn/vision-module.png" alt="Real-time Towel Recognition" /></p>

<p>로봇이 작업을 수행하려면 먼저 대상을 정확히 인식해야 합니다. 이를 위해 다양한 각도와 조명 조건에서 수건 이미지를 수집하고, OpenCV를 이용해 데이터를 증강하여 대규모 학습 데이터셋을 구축했습니다. ResNet, VGG 등 여러 CNN 아키텍처의 성능을 비교 평가한 결과, 인식 정확도와 속도 면에서 가장 우수한 <strong>ResNet152V2</strong>를 최종 모델로 선정했습니다. 이 모듈은 로봇 시스템의 ‘눈’ 역할을 하며, 실시간으로 입력되는 영상에서 안정적으로 수건의 위치를 파악합니다.</p>

<h2 id="2-강화학습-기반-접기-정책-학습">2. 강화학습 기반 접기 정책 학습</h2>

<p>[그림 2: 2D 시뮬레이션 환경에서의 학습 과정]
<img src="/assets/img/project-icros-dqn/rl-simulation.png" alt="RL Simulation Process" /></p>

<p>실제 로봇으로 수만 번의 학습을 진행하는 것은 비효율적이고 위험하기에, 먼저 가상의 2D 격자 환경(10x10 Grid World)을 직접 구축하여 문제를 단순화했습니다. 이 환경에서 로봇 에이전트는 강화학습 알고리즘인 <strong>DQN(Deep Q-Network)</strong>을 통해 최적의 접기 정책을 학습합니다.</p>

<ul>
  <li><strong>상태 (State):</strong> 2D 격자에서 수건이 차지하는 영역</li>
  <li><strong>행동 (Action):</strong> 상, 하, 좌, 우 네 방향으로 반을 접는 동작</li>
  <li><strong>보상 (Reward):</strong> 수건을 완전히 접는 목표 상태에 도달하면 큰 긍정적 보상을, 그 외의 행동에는 작은 부정적 보상(패널티)을 부여하여 최소한의 움직임으로 목표를 달성하도록 유도</li>
</ul>

<p>에이전트는 이 환경에서 무작위 탐색(Exploration)과 경험 기반 활용(Exploitation)을 반복하며, 점차 가장 효율적인 접기 순서를 터득하게 됩니다.</p>

<h2 id="3-실험-결과-및-분석">3. 실험 결과 및 분석</h2>

<ul>
  <li><strong>비전 모듈 성능:</strong> 개발된 비전 모듈은 다양한 배경과 조명 아래에서도 실시간으로 수건을 성공적으로 인식하며, 로봇 시스템의 입력 센서로서 충분한 안정성을 보였습니다.</li>
  <li><strong>정책 학습 성능:</strong> 2D 시뮬레이션 환경에서 학습된 DQN 에이전트는 <strong>평균 95%의 성공률</strong>로 수건을 최적의 순서대로 접는 정책을 학습하는 데 성공했습니다. 이는 강화학습이 순차적인 조작 문제를 해결하는 데 효과적임을 입증합니다.</li>
</ul>

<h2 id="4-결론-및-한계점">4. 결론 및 한계점</h2>

<h3 id="성과">성과</h3>
<ol>
  <li>CNN 기반 비전 인식과 DQN 기반 강화학습을 결합하여 비정형 객체(수건) 조작 작업을 자동화하는 접근법의 실현 가능성을 증명했습니다.</li>
  <li>복잡한 실제 문제를 2D 시뮬레이션으로 단순화하여, 강화학습 에이전트가 순차적 의사결정 문제를 처음부터 학습할 수 있음을 보였습니다.</li>
</ol>

<h3 id="한계점-및-향후-과제">한계점 및 향후 과제</h3>
<ul>
  <li><strong>Sim-to-Real Gap:</strong> 가장 큰 한계는 2D 시뮬레이션과 현실 세계의 물리적 차이입니다. 2D 격자 환경은 수건의 유연한 재질이나 구김 같은 복잡한 물리 현상을 반영하지 못합니다.</li>
  <li><strong>3D 시뮬레이션의 어려움:</strong> 이를 극복하고자 MuJoCo, Isaac Sim과 같은 3D 시뮬레이터 적용을 시도했으나, 부드러운 물체(Soft Body)의 물리 시뮬레이션이 매우 불안정하고 막대한 계산 자원을 요구하는 기술적 난관에 부딪혔습니다.</li>
</ul>

<p>이 연구는 제가 1저자로서 아이디어 구상부터 모델 설계, 실험, 논문 작성까지 전 과정을 주도한 첫 논문이라는 점에서 개인적으로 매우 의미가 깊습니다. 특히 3D 환경에서 비정형 객체를 다루는 것이 얼마나 어려운지 직접 체감한 이 경험은, 이후 KAIST 연구실에서 INR(Implicit Neural Representations)을 이용해 비정형 물체의 상태를 표현하는 연구에 도전하는 중요한 계기가 되었습니다.</p>

  </div>
  
    <div id="comments" style="margin-top: 4em;">
      <script src="https://giscus.app/client.js"
        data-repo="lemonzamong/lemonzamong.github.io"
        data-repo-id="R_kgDOP6FS1A"
        data-category="Comments"
        data-category-id="DIC_kwDOP6FS1M4CwIcQ"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="custom"
        data-lang="ko"
        crossorigin="anonymous"
        async>
</script>
    </div>
  
</div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://github.com/lemonzamong" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="https://www.linkedin.com/in/hyeokjun-kwon-6022912b1" target="_blank">
          <li>
            <i class="icon-linkedin-squared"></i>
          </li>
        </a><a href="https://instagram.com/jjjun_04" target="_blank">
          <li>
            <i class="icon-instagram"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>
